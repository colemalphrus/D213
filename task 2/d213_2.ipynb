{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# D213 Task 1 Advanced Data Analytics\n",
    "\n",
    "## Part 1\n",
    "\n",
    "### A1: Research Question and Data Selection\n",
    "\n",
    "Research Question:\n",
    "Is it possible to at accurately determine customer sentiment from a customers review utilizing Natural language processing and nural networks?\n",
    "\n",
    "Data and Rational:\n",
    "The data that will be used for this analysis is \"sentiment labeled sentences\" dataset which can be found at the link bellow. This data set provides a sentence representing a review along with a label of 1 or 0 indicating a positive or negative sentiment respectively\n",
    "\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/331/sentiment+labelled+sentences\n",
    "\n",
    "### A2: Objectives\n",
    "\n",
    "The objective of this analysis is to determine the feasibility of using a natural language processing neural network to determine a customers sentiment based on a review. The determination of feasibility will be made by creating a NLP model using Tensorflow. The objective of this model is to be able to take in the review text data and determine if the review has a positive or negative sentiment. \n",
    "\n",
    "### A3: Neural Network Type\n",
    "\n",
    "# TODO"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a432f0908da7590"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2\n",
    "\n",
    "### B1: Data Exploration and Cleaning\n",
    "\n",
    "1. Check presence of unusual characters\n",
    "2. Vocabulary size\n",
    "3. proposed word embedding length\n",
    "4. statistical justification for the chosen maximum sequence length\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d804fcb64e734f34"
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/orlandmalphrus/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Download Stopwords early to avoid rerunning\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T01:05:18.500103Z",
     "start_time": "2023-09-25T01:05:18.447686Z"
    }
   },
   "id": "5abee81299e7824a"
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon Count: 1000\n",
      "IMDB Count: 1000\n",
      "Yelp Count: 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                              review  score source\n0  So there is no way for me to plug it in here i...      0    amz\n1                        Good case, Excellent value.      1    amz\n2                             Great for the jawbone.      1    amz\n3  Tied to charger for conversations lasting more...      0    amz\n4                                  The mic is great.      1    amz",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>score</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>So there is no way for me to plug it in here i...</td>\n      <td>0</td>\n      <td>amz</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Good case, Excellent value.</td>\n      <td>1</td>\n      <td>amz</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Great for the jawbone.</td>\n      <td>1</td>\n      <td>amz</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Tied to charger for conversations lasting more...</td>\n      <td>0</td>\n      <td>amz</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The mic is great.</td>\n      <td>1</td>\n      <td>amz</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract data create combined dataframe and check counts\n",
    "amazon_df = pd.read_csv('./data/amazon_cells_labelled.txt', sep='\\t', names=['review', 'score'])\n",
    "imdb_df = pd.read_csv('./data/imdb_labelled.txt', sep='\\t', names=['review', 'score'])\n",
    "yelp_df = pd.read_csv('./data/yelp_labelled.txt', sep='\\t', names=['review', 'score'])\n",
    "\n",
    "print(f'Amazon Count: {amazon_df.shape[0]}')\n",
    "print(f'IMDB Count: {imdb_df.shape[0]}')\n",
    "print(f'Yelp Count: {yelp_df.shape[0]}')\n",
    "\n",
    "# Label Data Source\n",
    "amazon_df['source'] = 'amz'\n",
    "imdb_df['source'] = 'imdb'\n",
    "yelp_df['source'] = 'yelp'\n",
    "\n",
    "# Join Dataframes \n",
    "df = pd.concat([amazon_df, imdb_df, yelp_df], ignore_index=True)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T01:05:18.508962Z",
     "start_time": "2023-09-25T01:05:18.461277Z"
    }
   },
   "id": "6129db4b8935b16a"
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   review  3000 non-null   object\n",
      " 1   score   3000 non-null   int64 \n",
      " 2   source  3000 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 70.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T01:05:18.509308Z",
     "start_time": "2023-09-25T01:05:18.493654Z"
    }
   },
   "id": "2bb5843d8a8d76fd"
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Unique Characters:\n",
      "{'+', 'm', 'b', '8', 'p', 'I', 'A', 'v', ')', 'G', 'y', '[', 'é', 'V', 'å', '?', 'a', \"'\", 'x', '%', 'j', '6', '2', '5', '$', 'n', 's', 'f', '0', 'X', 'k', 'K', ' ', 'N', 'O', 'Y', 'w', '1', 'L', 'h', '4', '.', '*', 'q', 'r', 'E', 't', 'M', 'u', 'B', 'U', ';', 'c', '\\x97', '9', '\\x96', ']', '\"', 'W', '(', 'i', '&', '3', ':', 'C', 'S', 'ê', ',', 'J', '7', 'd', 'F', 'Z', 'H', 'P', '!', 'l', '#', '\\x85', 'D', 'z', 'g', 'e', 'T', '/', 'R', '-', 'Q', 'o'}\n"
     ]
    }
   ],
   "source": [
    "# Get all Unique chars from the dataset \n",
    "# Convert all reviews to a single string and then to a set to get unique characters\n",
    "unique_chars = set(''.join(df['review']))\n",
    "print('All Unique Characters:')\n",
    "print(unique_chars)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T01:05:18.509520Z",
     "start_time": "2023-09-25T01:05:18.507053Z"
    }
   },
   "id": "499675515bf4478c"
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non alpha numeric characters:\n",
      "['+', ')', '[', '?', \"'\", '%', '$', ' ', '.', '*', ';', '\\x97', '\\x96', ']', '\"', '(', '&', ':', ',', '!', '#', '\\x85', '/', '-']\n"
     ]
    }
   ],
   "source": [
    "non_alpha_numeric_chars = [char for char in unique_chars if not char.isalnum()]\n",
    "print('Non alpha numeric characters:')\n",
    "print(non_alpha_numeric_chars)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T01:05:18.510810Z",
     "start_time": "2023-09-25T01:05:18.508339Z"
    }
   },
   "id": "a20cef73165584a7"
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              review  score source  \\\n0  So there is no way for me to plug it in here i...      0    amz   \n1                        Good case, Excellent value.      1    amz   \n2                             Great for the jawbone.      1    amz   \n3  Tied to charger for conversations lasting more...      0    amz   \n4                                  The mic is great.      1    amz   \n\n                                      cleaned_review  \\\n0  So there is no way for me to plug it in here i...   \n1                          Good case Excellent value   \n2                              Great for the jawbone   \n3  Tied to charger for conversations lasting more...   \n4                                   The mic is great   \n\n                              cleaned_reduced_review  \n0                    way plug US unless go converter  \n1                          Good case Excellent value  \n2                                      Great jawbone  \n3  Tied charger conversations lasting 45 minutesM...  \n4                                          mic great  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>score</th>\n      <th>source</th>\n      <th>cleaned_review</th>\n      <th>cleaned_reduced_review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>So there is no way for me to plug it in here i...</td>\n      <td>0</td>\n      <td>amz</td>\n      <td>So there is no way for me to plug it in here i...</td>\n      <td>way plug US unless go converter</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Good case, Excellent value.</td>\n      <td>1</td>\n      <td>amz</td>\n      <td>Good case Excellent value</td>\n      <td>Good case Excellent value</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Great for the jawbone.</td>\n      <td>1</td>\n      <td>amz</td>\n      <td>Great for the jawbone</td>\n      <td>Great jawbone</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Tied to charger for conversations lasting more...</td>\n      <td>0</td>\n      <td>amz</td>\n      <td>Tied to charger for conversations lasting more...</td>\n      <td>Tied charger conversations lasting 45 minutesM...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The mic is great.</td>\n      <td>1</td>\n      <td>amz</td>\n      <td>The mic is great</td>\n      <td>mic great</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove non-alphanumeric chars\n",
    "df['cleaned_review'] = df['review'].apply(lambda x: ''.join([char for char in x if char.isalnum() or char.isspace()]))\n",
    "# Remove stopwords\n",
    "df['cleaned_reduced_review'] = df['cleaned_review'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T01:05:18.574137Z",
     "start_time": "2023-09-25T01:05:18.531974Z"
    }
   },
   "id": "ba493c94854dff61"
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 5276\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary Size\n",
    "all_words = ' '.join(df['cleaned_reduced_review']).lower().split()\n",
    "vocabulary = set(all_words)\n",
    "vocabulary_size =  len(vocabulary)\n",
    "print(f\"Vocabulary size: {vocabulary_size}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T01:05:18.607579Z",
     "start_time": "2023-09-25T01:05:18.538965Z"
    }
   },
   "id": "530926871244443c"
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed embedding length: 9\n"
     ]
    }
   ],
   "source": [
    "# Proposed word embedding length. Based on an industry rule of thumb for embeddings taking a forth root (Goldman, 2019)\n",
    "proposed_embedding_length = round(vocabulary_size ** .25)\n",
    "print(f\"Proposed embedding length: {proposed_embedding_length}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T01:05:18.608120Z",
     "start_time": "2023-09-25T01:05:18.541918Z"
    }
   },
   "id": "54e323678f716359"
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean clean_review_length: 11.777666666666667\n",
      "Standard deviation of clean_review_length: 7.8309221893934255\n",
      "Maximum clean_review_length: 70\n",
      "Suggested max sequence length: 27\n"
     ]
    }
   ],
   "source": [
    "# Justification of max sequence length\n",
    "df['cleaned_review_length'] = df['cleaned_review'].apply(lambda x: len(x.split()))\n",
    "clean_review_length_mean = df['cleaned_review_length'].mean()\n",
    "clean_review_length_std = df['cleaned_review_length'].std()\n",
    "clean_review_length_max = df['cleaned_review_length'].max()\n",
    "\n",
    "print(f\"Mean clean_review_length: {clean_review_length_mean}\")\n",
    "print(f\"Standard deviation of clean_review_length: {clean_review_length_std}\")\n",
    "print(f\"Maximum clean_review_length: {clean_review_length_max}\")\n",
    "\n",
    "# max length that covers around 95% of the dataset\n",
    "cutoff_length = int(clean_review_length_mean + 2 * clean_review_length_std)\n",
    "print(f\"Suggested max sequence length: {cutoff_length}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-25T01:05:18.608301Z",
     "start_time": "2023-09-25T01:05:18.559152Z"
    }
   },
   "id": "1a5bf26dffcdeeaa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### B2: Goal of tokenization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f43cc954a0476f6b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f07924fa8721ecef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
